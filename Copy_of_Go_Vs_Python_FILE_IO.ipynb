{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Go_Vs_Python_FILE_IO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/msDi6FY2yTZAzSqh2mzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhileswar-Komati/100D_ML/blob/master/Copy_of_Go_Vs_Python_FILE_IO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgvmbJIkfNuy"
      },
      "outputs": [],
      "source": [
        "from cassandra.cluster import Cluster, ExecutionProfile, EXEC_PROFILE_DEFAULT\n",
        "from cassandra.policies import WhiteListRoundRobinPolicy, DowngradingConsistencyRetryPolicy\n",
        "from cassandra.query import tuple_factory\n",
        "\n",
        "profile = ExecutionProfile(\n",
        "    load_balancing_policy=WhiteListRoundRobinPolicy(['127.0.0.1']),\n",
        "    retry_policy=DowngradingConsistencyRetryPolicy(),\n",
        "    consistency_level=ConsistencyLevel.LOCAL_QUORUM,\n",
        "    serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,\n",
        "    request_timeout=15,\n",
        "    row_factory=tuple_factory\n",
        ")\n",
        "cluster = Cluster(execution_profiles={EXEC_PROFILE_DEFAULT: profile})\n",
        "session = cluster.connect()\n",
        "\n",
        "print(session.execute(\"SELECT release_version FROM system.local\").one())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# df = pd.read_csv(\"from_2012.csv\")\n",
        "# print(df.shape)\n",
        "csv_reader1 = csv.reader(open(\"from_2012.csv\"))\n",
        "csv_reader2 = csv.reader(open(\"from_2012.csv\"))\n",
        "csv_reader3 = csv.reader(open(\"from_2012.csv\"))\n",
        "a = time.time()\n",
        "\n",
        "with open('file1.csv', 'w') as csvfile1:\n",
        "    csv_writer1 = csv.writer(csvfile1)\n",
        "    for row in csv_reader1:\n",
        "        csv_writer1.writerow(row)\n",
        "\n",
        "b = time.time()\n",
        "\n",
        "# with open('file2.csv', 'w') as csvfile2:\n",
        "#     csv_writer2 = csv.writer(csvfile2)\n",
        "\n",
        "#     i = 0\n",
        "#     rows = []\n",
        "#     for row in csv_reader2:\n",
        "#         i +=1\n",
        "#         rows.append(row)\n",
        "#         if i==10000:\n",
        "#             i = 0\n",
        "#             csv_writer2.writerows(rows)\n",
        "#             rows = []\n",
        "\n",
        "# c = time.time()\n",
        "\n",
        "# chunks = c-b\n",
        "# single = b-a\n",
        "# # print(c-b)\n",
        "# print(chunks, single, chunks>single)\n",
        "\n",
        "# a = time.time()\n",
        "\n",
        "# with open('file1.csv', 'w') as csvfile1:\n",
        "#     csv_writer1 = csv.writer(csvfile1)\n",
        "#     csv_writer1.writerows(csv_reader3)\n",
        "\n",
        "# b = time.time()\n",
        "\n",
        "print(b-a)"
      ],
      "metadata": {
        "id": "h5I0Tm0rfRg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "steps = [2, 10, 20]\n",
        "\n",
        "ind = 0\n",
        "for step in steps:\n",
        "    csv_reader = csv.reader(open(\"from_2012.csv\"))\n",
        "    b = time.time()\n",
        "    file_name = 'file{}.csv'.format(ind)\n",
        "    with open(file_name, 'w') as csvfile2:\n",
        "        csv_writer2 = csv.writer(csvfile2)\n",
        "\n",
        "        i = 0\n",
        "        rows = []\n",
        "        for row in csv_reader:\n",
        "            i +=1\n",
        "            rows.append(row)\n",
        "            if i==step:\n",
        "                i = 0\n",
        "                csv_writer2.writerows(rows)\n",
        "                rows = []\n",
        "    ind += 1\n",
        "    c = time.time()\n",
        "\n",
        "    chunks = c-b\n",
        "    print(chunks, file_name)\n"
      ],
      "metadata": {
        "id": "OP2pFx9sZ4Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "package main\n",
        "\n",
        "import (\n",
        "\t\"encoding/csv\"\n",
        "\t\"fmt\"\n",
        "\t\"log\"\n",
        "\t\"os\"\n",
        "\t\"time\"\n",
        ")\n",
        "\n",
        "func readCsvFile(filePath string) [][]string {\n",
        "\tf, err := os.Open(filePath)\n",
        "\tif err != nil {\n",
        "\t\tlog.Fatal(\"Unable to read input file \"+filePath, err)\n",
        "\t}\n",
        "\tdefer f.Close()\n",
        "\n",
        "\tcsvReader := csv.NewReader(f)\n",
        "\trecords, err := csvReader.ReadAll()\n",
        "\tif err != nil {\n",
        "\t\tlog.Fatal(\"Unable to parse file as CSV for \"+filePath, err)\n",
        "\t}\n",
        "\n",
        "\treturn records\n",
        "}\n",
        "\n",
        "func writeCsvFile(records [][]string, filePath string) {\n",
        "\tf, err := os.Create(filePath)\n",
        "\tif err != nil {\n",
        "\t\tlog.Fatalf(\"failed creating file: %s\", err)\n",
        "\t}\n",
        "\tdefer f.Close()\n",
        "\n",
        "\tcsvwriter := csv.NewWriter(f)\n",
        "\tfor _, record := range records {\n",
        "\t\t_ = csvwriter.Write(record)\n",
        "\t}\n",
        "\tcsvwriter.Flush()\n",
        "}\n",
        "\n",
        "func writeAllCsvFile(records [][]string, filePath string) {\n",
        "\tf, err := os.Create(filePath)\n",
        "\tif err != nil {\n",
        "\t\tlog.Fatalf(\"failed creating file: %s\", err)\n",
        "\t}\n",
        "\tdefer f.Close()\n",
        "\n",
        "\tcsvwriter := csv.NewWriter(f)\n",
        "\tcsvwriter.WriteAll(records)\n",
        "}\n",
        "\n",
        "func main() {\n",
        "\trecords := readCsvFile(\"from_2012.csv\")\n",
        "\tstart := time.Now()\n",
        "\twriteCsvFile(records, \"gofile.csv\")\n",
        "\tend := time.Now()\n",
        "\tfmt.Println(end.Sub(start))\n",
        "\tstart1 := time.Now()\n",
        "\twriteAllCsvFile(records, \"goallfile.csv\")\n",
        "\tend1 := time.Now()\n",
        "\tfmt.Println(end1.Sub(start1))\n",
        "}\n"
      ],
      "metadata": {
        "id": "Wqgnc1atZ5SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "package main\n",
        "\n",
        "import (\n",
        "\t\"fmt\"\n",
        "\t\"github.com/go-gota/gota/dataframe\"\n",
        "\t\"gonum.org/v1/gonum/mat\"\n",
        "\t// \"reflect\"\n",
        "\t\"github.com/pa-m/sklearn/preprocessing\"\n",
        "\t\"strings\"\n",
        "\t\"io/ioutil\"\n",
        ")\n",
        "\n",
        "type matrix struct {\n",
        "\tdataframe.DataFrame\n",
        "}\n",
        "\n",
        "func (m matrix) At(i, j int) float64 {\n",
        "\treturn m.Elem(i, j).Float()\n",
        "}\n",
        "\n",
        "func (m matrix) T() mat.Matrix {\n",
        "\treturn mat.Transpose{Matrix: m}\n",
        "}\n",
        "\n",
        "func getNumericalColumns(df dataframe.DataFrame) dataframe.DataFrame{\n",
        "\tlist_of_datatypes := df.Types()\n",
        "\tvar numerical_datatype_indexes []int\n",
        "\tfor indx, datatype := range list_of_datatypes {\n",
        "\t\tif datatype == \"float\" || datatype == \"int\" {\n",
        "\t\t\tnumerical_datatype_indexes = append(numerical_datatype_indexes, indx)\n",
        "\t\t}\n",
        "\t}\n",
        "\treturn df.Select(numerical_datatype_indexes)\n",
        "}\n",
        "\n",
        "func data_normalization_function(data dataframe.DataFrame, norm_type string, composite_columns []string) {\n",
        "\tfmt.Println(\"In Data Normalization\") \n",
        "\tnorm_type = strings.ToLower(norm_type)\n",
        "\tdata_without_time := data.Drop(composite_columns)\n",
        "\tdata_num := getNumericalColumns(data_without_time)\n",
        "\tdata_num_matrix := matrix{data_num}\n",
        "\tvar scaled_num_data *mat.Dense\n",
        "\tif norm_type == \"minmax\" {\n",
        "\t\tscaler := preprocessing.NewMinMaxScaler([]float64{0, 1})\n",
        "\t\tscaled_num_data, _ = scaler.FitTransform(data_num_matrix, nil)\n",
        "\t} else if norm_type == \"standard\" {\n",
        "\t\tscaler := preprocessing.NewStandardScaler()\n",
        "\t\tscaled_num_data, _ = scaler.FitTransform(data_num_matrix, nil)\n",
        "\t} else if norm_type == \"maxabs\" {\n",
        "\t\tscaler := preprocessing.NewMaxAbsScaler()\n",
        "\t\tscaled_num_data, _ = scaler.FitTransform(data_num_matrix, nil)\n",
        "\t} else if norm_type == \"robust\" {\n",
        "\t\tscaler := preprocessing.NewRobustScaler(true, false, nil)\n",
        "\t\tscaled_num_data, _ = scaler.FitTransform(data_num_matrix, nil)\n",
        "\t}\n",
        "\tfmt.Println(scaled_num_data)\n",
        "\tscaled_num_data_frame := dataframe.LoadMatrix(scaled_num_data)\n",
        "\tnum_column_names := data_num.Names()\n",
        "\tscaled_num_data_frame.SetNames(num_column_names...)\n",
        "\tfmt.Println(scaled_num_data_frame)\n",
        "\tdf_without_num_columns := data.Drop(num_column_names)\n",
        "\tdata = scaled_num_data_frame.CBind(df_without_num_columns)\n",
        "\tfmt.Println(data)\n",
        "}\n",
        "\n",
        "func main() {\n",
        "\tcontent, _ := ioutil.ReadFile(\"sample_go.csv\")\n",
        "\tioContent := strings.NewReader(string(content))\n",
        "\n",
        "\tdf := dataframe.ReadCSV(ioContent)\n",
        "\tnorm_type := \"minmax\"\n",
        "\tvar composite_columns []string\n",
        "\n",
        "\tdata_normalization_function(df, norm_type, composite_columns)\n",
        "}"
      ],
      "metadata": {
        "id": "K7pvQjmiAyGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "package main\n",
        "\n",
        "import (\n",
        "\t\"fmt\"\n",
        "\t\"github.com/go-gota/gota/dataframe\"\n",
        "\t\"gonum.org/v1/gonum/mat\"\n",
        "\t// \"reflect\"\n",
        "\t// \"github.com/pa-m/sklearn/preprocessing\"\n",
        "\t\"strings\"\n",
        "\t\"math\"\n",
        "\t\"io/ioutil\"\n",
        ")\n",
        "\n",
        "type matrix struct {\n",
        "\tdataframe.DataFrame\n",
        "}\n",
        "\n",
        "func (m matrix) At(i, j int) float64 {\n",
        "\treturn m.Elem(i, j).Float()\n",
        "}\n",
        "\n",
        "func (m matrix) T() mat.Matrix {\n",
        "\treturn mat.Transpose{Matrix: m}\n",
        "}\n",
        "\n",
        "func getNumericalColumns(df dataframe.DataFrame) dataframe.DataFrame{\n",
        "\tlist_of_datatypes := df.Types()\n",
        "\tvar numerical_datatype_indexes []int\n",
        "\tfor indx, datatype := range list_of_datatypes {\n",
        "\t\tif datatype == \"float\" || datatype == \"int\" {\n",
        "\t\t\tnumerical_datatype_indexes = append(numerical_datatype_indexes, indx)\n",
        "\t\t}\n",
        "\t}\n",
        "\treturn df.Select(numerical_datatype_indexes)\n",
        "}\n",
        "\n",
        "func replaceValuesInNumericColumns(df dataframe.DataFrame, old_value float64, new_value float64) dataframe.DataFrame{\n",
        "\tnum_df := getNumericalColumns(df)\n",
        "\tnum_column_names := num_df.Names()\n",
        "\tdata_num_matrix := matrix{num_df}\n",
        "\tdense_data_matrix := mat.DenseCopyOf(data_num_matrix)\n",
        "\t// fmt.Println(num_df.Names())\n",
        "\t// fmt.Println(dense_data_matrix)\n",
        "\t// fmt.Println(dense_data_matrix.IsEmpty())\n",
        "\t// fmt.Println(reflect.TypeOf(dense_data_matrix))\n",
        "\tnrows, ncols := dense_data_matrix.Dims()\n",
        "\tfor row := 0; row < nrows; row++ {\n",
        "\t\tfor col := 0; col < ncols; col++ {\n",
        "\t\t\tele := dense_data_matrix.At(row, col)\n",
        "\t\t\tif ele == old_value || math.IsNaN(ele){\n",
        "\t\t\t\tdense_data_matrix.Set(row, col, new_value)\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tnum_df = dataframe.LoadMatrix(dense_data_matrix)\n",
        "\tnum_df.SetNames(num_column_names...)\n",
        "\treturn num_df\n",
        "}\n",
        "\n",
        "func replaceValuesInCatColumns(df dataframe.DataFrame, old_value string, new_value string) dataframe.DataFrame {\n",
        "\tnum_df := getNumericalColumns(df)\n",
        "\tcat_df := df.Drop(num_df.Names())\n",
        "\tcat_column_names := cat_df.Names()\n",
        "\trecords := cat_df.Records()\n",
        "\tvar ele string\n",
        "\tfor row_indx, row := range records {\n",
        "\t\tfor col_indx, _ := range row {\n",
        "\t\t\tele = strings.ToLower(records[row_indx][col_indx])\n",
        "\t\t\tif ele == old_value || ele == \"\" {\n",
        "\t\t\t\trecords[row_indx][col_indx] = new_value\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\treturn dataframe.LoadRecords(records, dataframe.Names(cat_column_names...))\n",
        "}\n",
        "\n",
        "func replaceValuesInDataFrame(df dataframe.DataFrame, old_value float64, new_value float64) dataframe.DataFrame {\n",
        "\tvar df1 , df2 dataframe.DataFrame\n",
        "\tif math.IsNaN(old_value) {\n",
        "\t\tfmt.Println(\"--------------------Inside replace values in Df --------------------------\")\n",
        "\t\tdf1 = replaceValuesInCatColumns(df, \"nan\", \"0\")\n",
        "\t\tdf2 = replaceValuesInNumericColumns(df, old_value, new_value)\n",
        "\t} else {\n",
        "\t\tdf1 = replaceValuesInCatColumns(df, \"0\", \"nan\")\n",
        "\t\tdf2 = replaceValuesInNumericColumns(df, old_value, new_value)\n",
        "\t}\n",
        "\tdf = df1.CBind(df2)\n",
        "\treturn df\n",
        "}\n",
        "\n",
        "func dropNullValuesWithThreshold(data dataframe.DataFrame, threshold_count int) dataframe.DataFrame{\n",
        "\tnrows, ncols := data.Dims()\n",
        "\tvar non_null_counter int\n",
        "\tvar keep_indexes []int \n",
        "\tfmt.Println(\"Threshold = \", threshold_count)\n",
        "\tfor row := 0; row < nrows; row++ {\n",
        "\t\tnon_null_counter = 0\n",
        "\t\tfor col :=0; col < ncols; col++{\n",
        "\t\t\tele_float := data.Elem(row, col).Float()\n",
        "\t\t\tele_string := data.Elem(row, col).String()\n",
        "\t\t\tele_string = strings.ToLower(ele_string)\n",
        "\t\t\tfmt.Println(ele_float, ele_string)\n",
        "\t\t\tif !math.IsNaN(ele_float) || ele_string != \"nan\"{\n",
        "\t\t\t\tnon_null_counter += 1\n",
        "\t\t\t} \n",
        "\t\t}\n",
        "\t\tif non_null_counter >= threshold_count {\n",
        "\t\t\t//remove the row from matrix\n",
        "\t\t\tkeep_indexes = append(keep_indexes, row)\n",
        "\t\t}\n",
        "\t}\n",
        "\treturn data.Subset(keep_indexes)\n",
        "}\n",
        "\n",
        "func data_cleaning_function(data dataframe.DataFrame, cleaning_threshold int, is_zero_valid_data string) dataframe.DataFrame{\n",
        "\tfmt.Println(\"In Data Cleaning\") \n",
        "\tis_zero_valid_data = strings.ToLower(is_zero_valid_data)\n",
        "\tcolumn_names := data.Names()\n",
        "\tcolumn_length := len(column_names)\n",
        "\tvar cleaned_data_frame dataframe.DataFrame\n",
        "\tthreshold_count := column_length - int((column_length * cleaning_threshold)/100)\n",
        "\tif is_zero_valid_data == \"no\" {\n",
        "\t\t// fmt.Println(reflect.ValueOf(data_num_matrix))\n",
        "\t\tcleaned_data_frame = replaceValuesInDataFrame(data, 0, math.NaN())\n",
        "\t\tfmt.Println(cleaned_data_frame)\n",
        "\t\tfmt.Println(\"1st stage of cleaning done \")\n",
        "\t}\n",
        "\tcleaned_data_frame = dropNullValuesWithThreshold(cleaned_data_frame, threshold_count)\n",
        "\tfmt.Println(cleaned_data_frame)\n",
        "\tfmt.Println(\"dropping null values with threshold done\")\n",
        "\tif is_zero_valid_data == \"no\" {\n",
        "\t\tcleaned_data_frame = replaceValuesInDataFrame(cleaned_data_frame, math.NaN(), 0)\n",
        "\t\tfmt.Println(cleaned_data_frame)\n",
        "\t\tfmt.Println(\"2nd stage of cleaning done\")\n",
        "\t}\t\n",
        "\treturn cleaned_data_frame\n",
        "\n",
        "}\n",
        "\n",
        "func main() {\n",
        "\tcontent, _ := ioutil.ReadFile(\"sample_go.csv\")\n",
        "\tioContent := strings.NewReader(string(content))\n",
        "\tnan_values := []string {\"NA\", \"NaN\", \"<nil>\"}\n",
        "\tdf := dataframe.ReadCSV(ioContent, dataframe.NaNValues(nan_values))\n",
        "\tfmt.Println(df)\n",
        "\tcleaning_threshold := 30\n",
        "\tis_zero_valid_data := \"no\"\n",
        "\tfmt.Println(\"Data Cleaning Started\")\n",
        "\tcleaned_df := data_cleaning_function(df, cleaning_threshold, is_zero_valid_data)\n",
        "\tfmt.Println(cleaned_df)\n",
        "\tfmt.Println(\"Data Cleaning Done\")\n",
        "}"
      ],
      "metadata": {
        "id": "g7eoQA69MfHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "package main\n",
        "\n",
        "import (\n",
        "\t\"fmt\"\n",
        "\t\"github.com/go-gota/gota/dataframe\"\n",
        "\t\"github.com/go-gota/gota/series\"\n",
        "\t\"gonum.org/v1/gonum/mat\"\n",
        "\t// \"reflect\"\n",
        "\t\"github.com/pa-m/sklearn/preprocessing\"\n",
        "\t\"strings\"\n",
        "\t\"io/ioutil\"\n",
        "\t// \"math\"\n",
        ")\n",
        "\n",
        "type matrix struct {\n",
        "\tdataframe.DataFrame\n",
        "}\n",
        "\n",
        "func (m matrix) At(i, j int) float64 {\n",
        "\treturn m.Elem(i, j).Float()\n",
        "}\n",
        "\n",
        "func (m matrix) T() mat.Matrix {\n",
        "\treturn mat.Transpose{Matrix: m}\n",
        "}\n",
        "\n",
        "func uniqueElementsOfSlice(slice []string) []string {\n",
        "    // create a map with all the values as key\n",
        "    uniqMap := make(map[string]struct{})\n",
        "    for _, v := range slice {\n",
        "        uniqMap[v] = struct{}{}\n",
        "    }\n",
        "    // turn the map keys into a slice\n",
        "    uniqSlice := make([]string, 0, len(uniqMap))\n",
        "    for v := range uniqMap {\n",
        "        uniqSlice = append(uniqSlice, v)\n",
        "    }\n",
        "    return uniqSlice\n",
        "}\n",
        "\n",
        "func getNumericalColumns(df dataframe.DataFrame) dataframe.DataFrame{\n",
        "\tlist_of_datatypes := df.Types()\n",
        "\tvar numerical_datatype_indexes []int\n",
        "\tfor indx, datatype := range list_of_datatypes {\n",
        "\t\tif datatype == \"float\" || datatype == \"int\" {\n",
        "\t\t\tnumerical_datatype_indexes = append(numerical_datatype_indexes, indx)\n",
        "\t\t}\n",
        "\t}\n",
        "\treturn df.Select(numerical_datatype_indexes)\n",
        "}\n",
        "\n",
        "func data_imputation_function(data dataframe.DataFrame, impute_type string, composite_columns []string, is_zero_valid_data string, start_epoch int, end_epoch int) {\n",
        "\tfmt.Println(\"In Data Imputation\") \n",
        "\timpute_type = strings.ToLower(impute_type)\n",
        "\tis_zero_valid_data = strings.ToLower(is_zero_valid_data)\n",
        "\tdata_without_time := data.Drop(composite_columns)\n",
        "\tdata_num := getNumericalColumns(data_without_time)\n",
        "\tdata_num_matrix := matrix{data_num}\n",
        "\t// fmt.Println(data_num_matrix)\n",
        "\tif is_zero_valid_data == \"no\" {\n",
        "\t}\n",
        "\tif impute_type == \"mean\" || impute_type == \"median\" || impute_type == \"most_frequent\" {\n",
        "\t\timputed_model := &preprocessing.Imputer{Strategy: impute_type}\n",
        "\t\timputed_num_data, _ := imputed_model.FitTransform(data_num_matrix, nil)\n",
        "\t\t\n",
        "\t\t// fmt.Println(imputed_num_data)\n",
        "\t\timputed_num_data_frame := dataframe.LoadMatrix(imputed_num_data)\n",
        "\t\t// fmt.Println(imputed_num_data_frame)\n",
        "\t\tnum_column_names := data_num.Names()\n",
        "\t\timputed_num_data_frame.SetNames(num_column_names...)\n",
        "\t\t// fmt.Println(imputed_num_data_frame)\n",
        "\t\tdf_without_num_columns := data.Drop(num_column_names)\n",
        "\t\tdata = imputed_num_data_frame.CBind(df_without_num_columns)\n",
        "\t\tfmt.Println(data)\n",
        "\t} else if impute_type == \"medianoflast3days\" || impute_type == \"medianoflast3mins\" {\n",
        "\t\t// enbid_series := data.Col(\"ENBID\")\n",
        "\t\tenbid_series := data.Col(\"roll_num\")\n",
        "\t\tenbids := enbid_series.Records()\n",
        "\t\t// fmt.Println(uniqueElementsOfSlice(enbids))\n",
        "\t\tunique_enbids := uniqueElementsOfSlice(enbids)\n",
        "\t\tfor _, enbid := range unique_enbids {\n",
        "\t\t\tenb_data := data.Filter(dataframe.F{\n",
        "\t\t\t\tColname: \"ENBID\",\n",
        "\t\t\t\tComparator: series.Eq,\n",
        "\t\t\t\tComparando: enbid,\n",
        "\t\t\t})\n",
        "\t\t\tcells_series := enb_data.Col(\"CELLID\")\n",
        "\t\t\tcells := cells_series.Records()\n",
        "\t\t\tunique_cells := uniqueElementsOfSlice(cells)\n",
        "\t\t\tfor _, cell := range unique_cells {\n",
        "\t\t\t\tdf_data_num := data_import_cell_function(enb_data, start_epoch, end_epoch, impute_type, enbid, cell)\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\t\n",
        "}\n",
        "\n",
        "func main() {\n",
        "\tcontent, _ := ioutil.ReadFile(\"sample_go.csv\")\n",
        "\tioContent := strings.NewReader(string(content))\n",
        "\n",
        "\tdf := dataframe.ReadCSV(ioContent)\n",
        "\tvar impute_type, is_zero_valid_data string\n",
        "\tvar composite_columns []string\n",
        "\tvar start_epoch, end_epoch int\n",
        "\timpute_type = \"medianoflast3days\"\n",
        "\n",
        "\tdata_imputation_function(df, impute_type, composite_columns, is_zero_valid_data, start_epoch, end_epoch)\n",
        "}"
      ],
      "metadata": {
        "id": "9bDRqK0CMkEQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}